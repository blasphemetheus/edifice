defmodule Edifice.Generative.ScoreSDE do
  @moduledoc """
  Score-based SDE: Unified score matching framework for generative modeling.

  Implements the Score SDE framework from "Score-Based Generative Modeling
  through Stochastic Differential Equations" (Song et al., ICLR 2021).
  Unifies DDPM, SMLD, and other score-based methods under a single SDE
  perspective with two main variants:

  ## SDE Variants

  **VP-SDE** (Variance Preserving, generalizes DDPM):
  ```
  dx = -0.5 * beta(t) * x dt + sqrt(beta(t)) dw
  beta(t) = beta_min + t * (beta_max - beta_min)
  ```

  **VE-SDE** (Variance Exploding, generalizes SMLD):
  ```
  dx = sqrt(d[sigma^2(t)]/dt) dw
  sigma(t) = sigma_min * (sigma_max/sigma_min)^t
  ```

  ## Key Innovation: Score Function

  The score function s(x, t) = grad_x log p_t(x) is learned via denoising
  score matching. Once learned, samples are generated by solving the
  reverse-time SDE:

  ```
  dx = [-0.5 * beta(t) * x - beta(t) * s(x, t)] dt + sqrt(beta(t)) dw_rev
  ```

  Or the probability flow ODE (deterministic):
  ```
  dx = [-0.5 * beta(t) * x - 0.5 * beta(t) * s(x, t)] dt
  ```

  ## Architecture

  ```
  Input (x_t, t)
        |
        v
  +-----------------------+
  | Score Network         |
  | s_theta(x_t, t)       |
  |                       |
  | x_proj + time_embed   |
  | -> residual blocks    |
  | -> score prediction   |
  +-----------------------+
        |
        v
  Score [batch, input_dim]  (gradient of log density)
  ```

  ## Usage

      model = ScoreSDE.build(
        input_dim: 64,
        hidden_size: 256,
        num_layers: 4,
        sde_type: :vp
      )

      # Training: denoising score matching
      loss = ScoreSDE.dsm_loss(score_pred, noise, sigma)

  ## Reference

  - Paper: "Score-Based Generative Modeling through Stochastic Differential Equations"
  - arXiv: https://arxiv.org/abs/2011.13456
  """

  require Axon
  import Nx.Defn

  @default_hidden_size 256
  @default_num_layers 4
  @default_sde_type :vp
  # VP-SDE defaults
  @default_beta_min 0.1
  @default_beta_max 20.0
  # VE-SDE defaults
  @default_sigma_min 0.01
  @default_sigma_max 50.0

  @doc """
  Build a score network s(x, t) for the Score SDE framework.

  ## Options

    - `:input_dim` - Input feature dimension (required)
    - `:hidden_size` - Hidden dimension (default: 256)
    - `:num_layers` - Number of residual blocks (default: 4)
    - `:sde_type` - SDE variant: `:vp` or `:ve` (default: :vp)

  ## Returns

    An Axon model that predicts the score s(x, t) = grad_x log p_t(x).
  """
  @spec build(keyword()) :: Axon.t()
  def build(opts \\ []) do
    input_dim = Keyword.fetch!(opts, :input_dim)
    hidden_size = Keyword.get(opts, :hidden_size, @default_hidden_size)
    num_layers = Keyword.get(opts, :num_layers, @default_num_layers)
    _sde_type = Keyword.get(opts, :sde_type, @default_sde_type)

    # Inputs
    noisy_input = Axon.input("noisy_input", shape: {nil, input_dim})
    # t in [0, 1]
    timestep = Axon.input("timestep", shape: {nil})

    # Time embedding (Gaussian Fourier features for score networks)
    time_embed =
      Axon.layer(
        &fourier_time_embed_impl/2,
        [timestep],
        name: "time_embed",
        hidden_size: hidden_size,
        op_name: :fourier_embed
      )

    time_mlp =
      time_embed
      |> Axon.dense(hidden_size, name: "time_mlp_1")
      |> Axon.activation(:silu, name: "time_mlp_silu")
      |> Axon.dense(hidden_size, name: "time_mlp_2")

    # Input projection
    x_proj = Axon.dense(noisy_input, hidden_size, name: "input_proj")
    x_proj = Axon.activation(x_proj, :silu, name: "input_silu")

    # Combine via addition (FiLM-style conditioning)
    combined = Axon.add(x_proj, time_mlp, name: "combine")

    # Score prediction network
    x =
      Enum.reduce(1..num_layers, combined, fn idx, acc ->
        build_score_block(acc, hidden_size, "score_block_#{idx}")
      end)

    x = Axon.layer_norm(x, name: "final_norm")

    # Output: score s(x, t) has same dimension as input
    Axon.dense(x, input_dim, name: "score_output")
  end

  defp build_score_block(input, hidden_size, name) do
    x = Axon.layer_norm(input, name: "#{name}_norm")
    x = Axon.dense(x, hidden_size * 4, name: "#{name}_up")
    x = Axon.activation(x, :silu, name: "#{name}_silu")
    x = Axon.dense(x, hidden_size, name: "#{name}_down")
    Axon.add(input, x, name: "#{name}_residual")
  end

  # Gaussian Fourier features for time embedding (better than sinusoidal for scores)
  defp fourier_time_embed_impl(t, opts) do
    hidden_size = opts[:hidden_size]
    half_dim = div(hidden_size, 2)

    # Random Fourier features with learned-like fixed frequencies
    freqs =
      Nx.multiply(
        Nx.tensor(:math.pi() * 2),
        Nx.exp(
          Nx.multiply(
            Nx.log(Nx.tensor(100.0)),
            Nx.divide(Nx.iota({half_dim}, type: :f32), max(half_dim - 1, 1))
          )
        )
      )

    t_expanded = Nx.new_axis(Nx.as_type(t, :f32), 1)
    angles = Nx.multiply(t_expanded, Nx.reshape(freqs, {1, half_dim}))
    Nx.concatenate([Nx.sin(angles), Nx.cos(angles)], axis: 1)
  end

  # ============================================================================
  # SDE Schedules
  # ============================================================================

  @doc """
  VP-SDE noise schedule.

  beta(t) = beta_min + t * (beta_max - beta_min)

  ## Options

    - `:beta_min` - Minimum beta (default: 0.1)
    - `:beta_max` - Maximum beta (default: 20.0)

  ## Returns

    Schedule map with perturbation and marginal functions.
  """
  @spec vp_schedule(keyword()) :: map()
  def vp_schedule(opts \\ []) do
    beta_min = Keyword.get(opts, :beta_min, @default_beta_min)
    beta_max = Keyword.get(opts, :beta_max, @default_beta_max)

    %{
      type: :vp,
      beta_min: beta_min,
      beta_max: beta_max
    }
  end

  @doc """
  VE-SDE noise schedule.

  sigma(t) = sigma_min * (sigma_max / sigma_min)^t

  ## Options

    - `:sigma_min` - Minimum sigma (default: 0.01)
    - `:sigma_max` - Maximum sigma (default: 50.0)

  ## Returns

    Schedule map.
  """
  @spec ve_schedule(keyword()) :: map()
  def ve_schedule(opts \\ []) do
    sigma_min = Keyword.get(opts, :sigma_min, @default_sigma_min)
    sigma_max = Keyword.get(opts, :sigma_max, @default_sigma_max)

    %{
      type: :ve,
      sigma_min: sigma_min,
      sigma_max: sigma_max
    }
  end

  @doc """
  Compute the marginal distribution parameters at time t for VP-SDE.

  For VP-SDE: p(x_t | x_0) = N(x_t; alpha(t) * x_0, sigma(t)^2 * I)
  where alpha(t) = exp(-0.5 * integral(beta, 0, t))
  """
  @spec vp_marginal(Nx.Tensor.t(), map()) :: {Nx.Tensor.t(), Nx.Tensor.t()}
  defn vp_marginal(t, schedule) do
    beta_min = schedule.beta_min
    beta_max = schedule.beta_max

    # Integral of beta(s) from 0 to t = beta_min*t + 0.5*(beta_max-beta_min)*t^2
    log_mean_coeff = -0.25 * t * t * (beta_max - beta_min) - 0.5 * t * beta_min
    mean_coeff = Nx.exp(log_mean_coeff)
    std = Nx.sqrt(1.0 - Nx.exp(2.0 * log_mean_coeff))

    {mean_coeff, std}
  end

  @doc """
  Compute the noise level sigma at time t for VE-SDE.

  sigma(t) = sigma_min * (sigma_max / sigma_min)^t
  """
  @spec ve_sigma(Nx.Tensor.t(), map()) :: Nx.Tensor.t()
  defn ve_sigma(t, schedule) do
    sigma_min = schedule.sigma_min
    sigma_max = schedule.sigma_max

    sigma_min * Nx.pow(sigma_max / sigma_min, t)
  end

  # ============================================================================
  # Training Loss
  # ============================================================================

  @doc """
  Denoising score matching loss.

  The score at noise level sigma is: s(x_t) = -(x_t - x_0) / sigma^2
  Train by minimizing: E[sigma^2 * ||s_theta(x_t, t) + (x_t - x_0)/sigma^2||^2]

  ## Parameters

    - `score_pred` - Predicted score s_theta(x_t, t)
    - `noise` - The noise added (epsilon)
    - `sigma` - Noise standard deviation at this timestep

  ## Returns

    Scalar loss.
  """
  @spec dsm_loss(Nx.Tensor.t(), Nx.Tensor.t(), Nx.Tensor.t()) :: Nx.Tensor.t()
  defn dsm_loss(score_pred, noise, sigma) do
    # True score = -noise / sigma
    sigma_2d = Nx.new_axis(sigma, 1)
    target_score = Nx.negate(Nx.divide(noise, Nx.add(sigma_2d, 1.0e-8)))

    # Weighted MSE (weight by sigma^2 for scale invariance)
    diff = Nx.subtract(score_pred, target_score)
    weighted = Nx.multiply(sigma_2d * sigma_2d, Nx.multiply(diff, diff))
    Nx.mean(weighted)
  end

  # ============================================================================
  # Utilities
  # ============================================================================

  @doc """
  Get the output size of a Score SDE model.
  """
  @spec output_size(keyword()) :: non_neg_integer()
  def output_size(opts \\ []) do
    Keyword.get(opts, :input_dim, 64)
  end

  @doc """
  Calculate approximate parameter count.
  """
  @spec param_count(keyword()) :: non_neg_integer()
  def param_count(opts) do
    input_dim = Keyword.get(opts, :input_dim, 64)
    hidden_size = Keyword.get(opts, :hidden_size, @default_hidden_size)
    num_layers = Keyword.get(opts, :num_layers, @default_num_layers)

    input_proj = input_dim * hidden_size
    time_mlp = 2 * hidden_size * hidden_size
    blocks = num_layers * (hidden_size * hidden_size * 4 + hidden_size * 4 * hidden_size)
    output_proj = hidden_size * input_dim

    input_proj + time_mlp + blocks + output_proj
  end

  @doc """
  Get recommended defaults.
  """
  @spec recommended_defaults() :: keyword()
  def recommended_defaults do
    [
      input_dim: 64,
      hidden_size: 256,
      num_layers: 4,
      sde_type: :vp,
      beta_min: 0.1,
      beta_max: 20.0
    ]
  end
end
